{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Topic extraction</b>\n",
    "\n",
    "<i>The code below can be used for the topic extraction. Here, it uses a sentence transformer fine-tuned for multilingual data. However, if you want to use a different sentence transformer, just change the model to another one of the sentence transformers (<a href=\"https://www.sbert.net/\" target=\"_blank\">sentence transformers</a>). It is also possible to use a transformer not made for sentences, but for words (<a href=\"https://huggingface.co/models\" target=\"_blank\">huggingface transformers</a>). The transformer is used to vectorize the text into a high-dimensional vector space, so the computer is able to read the data.\n",
    "\n",
    "Further, this script uses BERTopic to automatically create clusters of tweets (using HDBSCAN and c-TF-IDF).</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import needed libraries: \n",
    "    #pandas for reading the daa\n",
    "    #sentence_transformers for using a sentence transformer\n",
    "    #bertopic for extracting topics\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import plotly.express as px\n",
    "from umap import UMAP\n",
    "\n",
    "#Set csv file to variable\n",
    "outputgermany = pd.read_csv('Data\\\\filtered_tweets_germany.csv')\n",
    "\n",
    "#Read the data with pandas and transform it to dataframe\n",
    "tweets_germany = pd.DataFrame(outputgermany)\n",
    "\n",
    "#Set embedding model to transformer you want to use\n",
    "model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "#Set random state variable to make sure results are reproducible\n",
    "umap_model = UMAP(random_state=42)\n",
    "\n",
    "#Set BERTopic model\n",
    "    #embedding_model is your sentence transformer\n",
    "    #min_topic_size: how many tweets the cluster must contain before creating a cluster\n",
    "    #verbose=True means that you are able to see how far the model is when executing\n",
    "topic_model = BERTopic(embedding_model=model, min_topic_size=70, verbose=True, umap_model=umap_model)\n",
    "\n",
    "#Transform text into embeddings and create clusters \n",
    "    #Between the parathenses, define the text to create embeddings and clusters on\n",
    "topics, probs = topic_model.fit_transform(tweets_germany['text_clean'])\n",
    "\n",
    "#Add the created topics to the dataframe\n",
    "clusters_pd = pd.DataFrame(topics,columns=['clusters'])\n",
    "clusters_pd.value_counts()\n",
    "tweets_germany['Topic'] = clusters_pd\n",
    "\n",
    "#Then, a time analysis can be performed on the topics\n",
    "topics_over_time = topic_model.topics_over_time(tweets_germany['text_clean'], topics, tweets_germany['Date'], nr_bins=50)\n",
    "\n",
    "#Visualize the time analysis in a graph\n",
    "topicovertime = topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)\n",
    "\n",
    "#Save dynamic figure as html file\n",
    "topicovertime.write_html(\"Data\\\\topic70overtime.html\")\n",
    "\n",
    "#Save model\n",
    "topic_model.save(\"time_bertopic70\")\n",
    "\n",
    "#Save dataframe as csv\n",
    "tweets_germany.to_csv('Data\\\\topics70_tweets_germany.csv', index = False, header='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can be used to retrieve information about the created clusters. See the documentation on <a href=\"https://maartengr.github.io/BERTopic/index.html\" target=\"_blank\">BERTopic</a> for more visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic.load('time_bertopic70')\n",
    "\n",
    "topic_model.get_topic_info()\n",
    "\n",
    "topic_model.get_topic(10)\n",
    "\n",
    "topic_model.get_representative_docs(13)\n",
    "\n",
    "topic_model.visualize_topics()\n",
    "\n",
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create wordcloud with all keywords of each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Set image for the wordcloud\n",
    "mask2 = np.array(Image.open(\"Data\\\\duitslandwordcloud.png\"))\n",
    "\n",
    "#Create function for the generation of the wordcloud\n",
    "    #Data is dictionary containing words + probabilities\n",
    "    #Title is name of the wordcloud\n",
    "    #name is how you want the png file to be saved\n",
    "    \n",
    "def generate_wordcloud(data, title, name):\n",
    "    wordcloud = WordCloud(background_color='white', prefer_horizontal=1, contour_color='black', contour_width=1).generate_from_frequencies(data)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    wordcloud.to_file(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corona and policies wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic0words = topic_model.get_topic(0)\n",
    "topic0wordsdf = pd.DataFrame(topic0words, columns=['word', 'probs'])\n",
    "topic0wordsdf['word'] = topic0wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic0 = {}\n",
    "for word, probs in topic0wordsdf.values:\n",
    "    topic0[word] = probs\n",
    "\n",
    "topic2words = topic_model.get_topic(2)\n",
    "topic2wordsdf = pd.DataFrame(topic2words, columns=['word', 'probs'])\n",
    "topic2wordsdf['word'] = topic2wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic2 = {}\n",
    "for word, probs in topic2wordsdf.values:\n",
    "    topic2[word] = probs\n",
    "\n",
    "topic4words = topic_model.get_topic(4)\n",
    "topic4wordsdf = pd.DataFrame(topic4words, columns=['word', 'probs'])\n",
    "topic4wordsdf['word'] = topic4wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic4 = {}\n",
    "for word, probs in topic4wordsdf.values:\n",
    "    topic4[word] = probs\n",
    "\n",
    "topic6words = topic_model.get_topic(6)\n",
    "topic6wordsdf = pd.DataFrame(topic6words, columns=['word', 'probs'])\n",
    "topic6wordsdf['word'] = topic6wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic6 = {}\n",
    "for word, probs in topic6wordsdf.values:\n",
    "    topic6[word] = probs\n",
    "\n",
    "topic13words = topic_model.get_topic(13)\n",
    "topic13wordsdf = pd.DataFrame(topic13words, columns=['word', 'probs'])\n",
    "topic13wordsdf['word'] = topic13wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic13 = {}\n",
    "for word, probs in topic13wordsdf.values:\n",
    "    topic13[word] = probs\n",
    "\n",
    "coronapolicies = {**topic0, **topic2, **topic4, **topic6, **topic13}\n",
    "\n",
    "coronapolicieswordcloud = generate_wordcloud(coronapolicies, 'Corona and policies', 'Wordclouds\\\\coronapolicieswordcloud.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lockdown activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic3words = topic_model.get_topic(3)\n",
    "topic3wordsdf = pd.DataFrame(topic3words, columns=['word', 'probs'])\n",
    "topic3wordsdf['word'] = topic3wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic3 = {}\n",
    "for word, probs in topic3wordsdf.values:\n",
    "    topic3[word] = probs\n",
    "\n",
    "topic7words = topic_model.get_topic(7)\n",
    "topic7wordsdf = pd.DataFrame(topic7words, columns=['word', 'probs'])\n",
    "topic7wordsdf['word'] = topic7wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic7 = {}\n",
    "for word, probs in topic7wordsdf.values:\n",
    "    topic7[word] = probs\n",
    "\n",
    "topic8words = topic_model.get_topic(8)\n",
    "topic8wordsdf = pd.DataFrame(topic8words, columns=['word', 'probs'])\n",
    "topic8wordsdf['word'] = topic8wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic8 = {}\n",
    "for word, probs in topic8wordsdf.values:\n",
    "    topic8[word] = probs\n",
    "\n",
    "topic9words = topic_model.get_topic(9)\n",
    "topic9wordsdf = pd.DataFrame(topic9words, columns=['word', 'probs'])\n",
    "topic9wordsdf['word'] = topic9wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic9 = {}\n",
    "for word, probs in topic9wordsdf.values:\n",
    "    topic9[word] = probs\n",
    "\n",
    "topic11words = topic_model.get_topic(11)\n",
    "topic11wordsdf = pd.DataFrame(topic11words, columns=['word', 'probs'])\n",
    "topic11wordsdf['word'] = topic11wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic11 = {}\n",
    "for word, probs in topic11wordsdf.values:\n",
    "    topic11[word] = probs\n",
    "\n",
    "topic12words = topic_model.get_topic(12)\n",
    "topic12wordsdf = pd.DataFrame(topic12words, columns=['word', 'probs'])\n",
    "topic12wordsdf['word'] = topic12wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic12 = {}\n",
    "for word, probs in topic12wordsdf.values:\n",
    "    topic12[word] = probs\n",
    "\n",
    "\n",
    "lockdownactivities = {**topic3, **topic7, **topic8, **topic9, **topic11, **topic12}\n",
    "\n",
    "lockdownactivitieswordcloud = generate_wordcloud(lockdownactivities, 'Lockdown activities', 'Wordclouds\\\\lockdownactivitieswordcloud.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic1words = topic_model.get_topic(1)\n",
    "topic1wordsdf = pd.DataFrame(topic1words, columns=['word', 'probs'])\n",
    "topic1wordsdf['word'] = topic1wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic1 = {}\n",
    "for word, probs in topic1wordsdf.values:\n",
    "    topic1[word] = probs\n",
    "\n",
    "\n",
    "topic5words = topic_model.get_topic(5)\n",
    "topic5wordsdf = pd.DataFrame(topic5words, columns=['word', 'probs'])\n",
    "topic5wordsdf['word'] = topic5wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic5 = {}\n",
    "for word, probs in topic5wordsdf.values:\n",
    "    topic5[word] = probs\n",
    "\n",
    "topic10words = topic_model.get_topic(10)\n",
    "topic10wordsdf = pd.DataFrame(topic10words, columns=['word', 'probs'])\n",
    "topic10wordsdf['word'] = topic10wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic10 = {}\n",
    "for word, probs in topic10wordsdf.values:\n",
    "    topic10[word] = probs\n",
    "\n",
    "\n",
    "topic14words = topic_model.get_topic(14)\n",
    "topic14wordsdf = pd.DataFrame(topic14words, columns=['word', 'probs'])\n",
    "topic14wordsdf['word'] = topic14wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic14 = {}\n",
    "for word, probs in topic14wordsdf.values:\n",
    "    topic14[word] = probs\n",
    "\n",
    "topic15words = topic_model.get_topic(15)\n",
    "topic15wordsdf = pd.DataFrame(topic15words, columns=['word', 'probs'])\n",
    "topic15wordsdf['word'] = topic15wordsdf['word'].astype(\"string\")\n",
    "\n",
    "topic15 = {}\n",
    "for word, probs in topic15wordsdf.values:\n",
    "    topic15[word] = probs\n",
    "\n",
    "prevention = {**topic1, **topic5, **topic10, **topic14, **topic15}\n",
    "preventionwordcloud = generate_wordcloud(prevention, 'Prevention', 'Wordclouds\\\\preventionwordcloud.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1638be7ebbf05af5870fdc927cbfd7e5796b8b306115e1f4a5e53bb99b67796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
